{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09bd3da2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-28T19:39:22.773165Z",
     "iopub.status.busy": "2025-06-28T19:39:22.772875Z",
     "iopub.status.idle": "2025-06-28T19:39:23.332464Z",
     "shell.execute_reply": "2025-06-28T19:39:23.331517Z"
    },
    "id": "NAEMiZI0EbKX",
    "outputId": "67c718dd-09c0-41ae-ade5-e2a730d1ab76",
    "papermill": {
     "duration": 0.569379,
     "end_time": "2025-06-28T19:39:23.333943",
     "exception": false,
     "start_time": "2025-06-28T19:39:22.764564",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data source import complete.\n"
     ]
    }
   ],
   "source": [
    "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
    "# THEN FEEL FREE TO DELETE THIS CELL.\n",
    "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
    "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
    "# NOTEBOOK.\n",
    "import os\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
    "\n",
    "import kagglehub\n",
    "snap_amazon_fine_food_reviews_path = kagglehub.dataset_download('snap/amazon-fine-food-reviews')\n",
    "\n",
    "print('Data source import complete.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd665e3c",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-06-28T19:39:23.348651Z",
     "iopub.status.busy": "2025-06-28T19:39:23.347971Z",
     "iopub.status.idle": "2025-06-28T19:39:25.143084Z",
     "shell.execute_reply": "2025-06-28T19:39:25.141910Z"
    },
    "id": "PV6dqk3-EbKZ",
    "outputId": "9bd2b640-d410-445b-b1be-3c1ef40af092",
    "papermill": {
     "duration": 1.804298,
     "end_time": "2025-06-28T19:39:25.145085",
     "exception": false,
     "start_time": "2025-06-28T19:39:23.340787",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/amazon-fine-food-reviews/hashes.txt\n",
      "/kaggle/input/amazon-fine-food-reviews/Reviews.csv\n",
      "/kaggle/input/amazon-fine-food-reviews/database.sqlite\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3aa2c371",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-28T19:39:25.159381Z",
     "iopub.status.busy": "2025-06-28T19:39:25.158949Z",
     "iopub.status.idle": "2025-06-28T19:39:46.676743Z",
     "shell.execute_reply": "2025-06-28T19:39:46.675787Z"
    },
    "id": "Qsz-C4hlEbKb",
    "papermill": {
     "duration": 21.52664,
     "end_time": "2025-06-28T19:39:46.678430",
     "exception": false,
     "start_time": "2025-06-28T19:39:25.151790",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-28 19:39:31.883322: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1751139572.104647      13 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1751139572.170809      13 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90a8f58a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-28T19:39:46.693772Z",
     "iopub.status.busy": "2025-06-28T19:39:46.693138Z",
     "iopub.status.idle": "2025-06-28T19:39:46.697624Z",
     "shell.execute_reply": "2025-06-28T19:39:46.696849Z"
    },
    "papermill": {
     "duration": 0.013279,
     "end_time": "2025-06-28T19:39:46.698947",
     "exception": false,
     "start_time": "2025-06-28T19:39:46.685668",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3dd351cc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-28T19:39:46.712475Z",
     "iopub.status.busy": "2025-06-28T19:39:46.712177Z",
     "iopub.status.idle": "2025-06-28T19:39:54.662282Z",
     "shell.execute_reply": "2025-06-28T19:39:54.661511Z"
    },
    "id": "eHAKt5GNEbKc",
    "papermill": {
     "duration": 7.95879,
     "end_time": "2025-06-28T19:39:54.663996",
     "exception": false,
     "start_time": "2025-06-28T19:39:46.705206",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#preparing the data ready for the  transformer\n",
    "data = pd.read_csv('/kaggle/input/amazon-fine-food-reviews/Reviews.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "212911d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-28T19:39:54.679212Z",
     "iopub.status.busy": "2025-06-28T19:39:54.678927Z",
     "iopub.status.idle": "2025-06-28T19:39:54.683546Z",
     "shell.execute_reply": "2025-06-28T19:39:54.682791Z"
    },
    "id": "FnhfDdOAEbKc",
    "papermill": {
     "duration": 0.013642,
     "end_time": "2025-06-28T19:39:54.684880",
     "exception": false,
     "start_time": "2025-06-28T19:39:54.671238",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_train = data.iloc[:3000, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0a54817",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-28T19:39:54.699274Z",
     "iopub.status.busy": "2025-06-28T19:39:54.698993Z",
     "iopub.status.idle": "2025-06-28T19:39:54.719847Z",
     "shell.execute_reply": "2025-06-28T19:39:54.718917Z"
    },
    "id": "0pi5wMO7EbKd",
    "papermill": {
     "duration": 0.029602,
     "end_time": "2025-06-28T19:39:54.721468",
     "exception": false,
     "start_time": "2025-06-28T19:39:54.691866",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "#preparing the inputs and the outputs from the data\n",
    "\n",
    "inputs = [];\n",
    "text=\"\";\n",
    "\n",
    "output = [];\n",
    "text2=\"\";\n",
    "for row in np.array(data_train.iloc[:, :]):\n",
    "    if len(row[-1])> 300:\n",
    "        continue;\n",
    "\n",
    "    inputs.append(row[-1])\n",
    "    text = text+ row[-1];\n",
    "    output.append(row[-2])\n",
    "    text2 = text2+ row[-2];\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df33817e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-28T19:39:54.735600Z",
     "iopub.status.busy": "2025-06-28T19:39:54.735285Z",
     "iopub.status.idle": "2025-06-28T19:39:54.741387Z",
     "shell.execute_reply": "2025-06-28T19:39:54.740661Z"
    },
    "id": "SnyLLSC-6CGT",
    "outputId": "ccef3322-49ce-45d0-f3b7-02b7e91931ce",
    "papermill": {
     "duration": 0.01488,
     "end_time": "2025-06-28T19:39:54.742933",
     "exception": false,
     "start_time": "2025-06-28T19:39:54.728053",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Good Quality Dog Food'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7bd43ae0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-28T19:39:54.758049Z",
     "iopub.status.busy": "2025-06-28T19:39:54.757323Z",
     "iopub.status.idle": "2025-06-28T19:39:54.765718Z",
     "shell.execute_reply": "2025-06-28T19:39:54.764702Z"
    },
    "id": "wpMfMOB34Kg3",
    "outputId": "92fded7f-36a0-4841-dfc8-56a50576228a",
    "papermill": {
     "duration": 0.017442,
     "end_time": "2025-06-28T19:39:54.767048",
     "exception": false,
     "start_time": "2025-06-28T19:39:54.749606",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13/3301232396.py:1: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  data_train.iloc[20, :][-1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"My husband is a Twizzlers addict.  We've bought these many times from Amazon because we're government employees living overseas and can't get them in the country we are assigned to.  They've always been fresh and tasty, packed well and arrive in a timely manner.\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.iloc[20, :][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5e460582",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-28T19:39:54.781342Z",
     "iopub.status.busy": "2025-06-28T19:39:54.781065Z",
     "iopub.status.idle": "2025-06-28T19:39:54.786457Z",
     "shell.execute_reply": "2025-06-28T19:39:54.785546Z"
    },
    "id": "EbSXawIEEbKe",
    "outputId": "4badebcf-4a6a-4e2e-daf8-7af8342b5150",
    "papermill": {
     "duration": 0.013987,
     "end_time": "2025-06-28T19:39:54.787822",
     "exception": false,
     "start_time": "2025-06-28T19:39:54.773835",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n",
      "98\n"
     ]
    }
   ],
   "source": [
    "print(max([len(x) for x in inputs]))\n",
    "print(max([len(x) for x in output]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "327ead54",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-28T19:39:54.802063Z",
     "iopub.status.busy": "2025-06-28T19:39:54.801766Z",
     "iopub.status.idle": "2025-06-28T19:39:54.879626Z",
     "shell.execute_reply": "2025-06-28T19:39:54.878683Z"
    },
    "id": "LffE73MnEbKf",
    "papermill": {
     "duration": 0.08692,
     "end_time": "2025-06-28T19:39:54.881372",
     "exception": false,
     "start_time": "2025-06-28T19:39:54.794452",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#tokenizer to fit the input tokens\n",
    "tokenizer = Tokenizer();\n",
    "\n",
    "X = [];\n",
    "\n",
    "tokenizer.fit_on_texts(inputs);\n",
    "sequences = tokenizer.texts_to_sequences(inputs);\n",
    "for sequence in sequences:\n",
    "    X.append(sequence);\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2a9b12a1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-28T19:39:54.896434Z",
     "iopub.status.busy": "2025-06-28T19:39:54.895749Z",
     "iopub.status.idle": "2025-06-28T19:39:54.926324Z",
     "shell.execute_reply": "2025-06-28T19:39:54.925612Z"
    },
    "id": "0cV4urT-Iu00",
    "papermill": {
     "duration": 0.039587,
     "end_time": "2025-06-28T19:39:54.927731",
     "exception": false,
     "start_time": "2025-06-28T19:39:54.888144",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#tokenizer to fit the output tokens\n",
    "token_out = Tokenizer();\n",
    "Y = [];\n",
    "token_out.fit_on_texts(output);\n",
    "sequences = token_out.texts_to_sequences(output);\n",
    "for sequence in sequences:\n",
    "    Y.append(sequence);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fcbcfd72",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-28T19:39:54.942468Z",
     "iopub.status.busy": "2025-06-28T19:39:54.941790Z",
     "iopub.status.idle": "2025-06-28T19:39:54.947451Z",
     "shell.execute_reply": "2025-06-28T19:39:54.946802Z"
    },
    "papermill": {
     "duration": 0.014441,
     "end_time": "2025-06-28T19:39:54.948801",
     "exception": false,
     "start_time": "2025-06-28T19:39:54.934360",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1397"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max([max(i) for i in Y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b6ede5cd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-28T19:39:54.963770Z",
     "iopub.status.busy": "2025-06-28T19:39:54.963057Z",
     "iopub.status.idle": "2025-06-28T19:39:54.967366Z",
     "shell.execute_reply": "2025-06-28T19:39:54.966685Z"
    },
    "papermill": {
     "duration": 0.012969,
     "end_time": "2025-06-28T19:39:54.968719",
     "exception": false,
     "start_time": "2025-06-28T19:39:54.955750",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "maxx = min( [min(i) for i in Y] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "949582af",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-28T19:39:54.983755Z",
     "iopub.status.busy": "2025-06-28T19:39:54.983097Z",
     "iopub.status.idle": "2025-06-28T19:39:54.988190Z",
     "shell.execute_reply": "2025-06-28T19:39:54.987553Z"
    },
    "papermill": {
     "duration": 0.013789,
     "end_time": "2025-06-28T19:39:54.989410",
     "exception": false,
     "start_time": "2025-06-28T19:39:54.975621",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0d0f26ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-28T19:39:55.004421Z",
     "iopub.status.busy": "2025-06-28T19:39:55.003906Z",
     "iopub.status.idle": "2025-06-28T19:39:55.009440Z",
     "shell.execute_reply": "2025-06-28T19:39:55.008579Z"
    },
    "id": "N4E2cp8RyTyl",
    "outputId": "3895ea18-5b8f-4a40-f2db-1f46e141f09d",
    "papermill": {
     "duration": 0.014467,
     "end_time": "2025-06-28T19:39:55.010857",
     "exception": false,
     "start_time": "2025-06-28T19:39:54.996390",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1397"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(token_out.word_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "95a6645e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-28T19:39:55.026311Z",
     "iopub.status.busy": "2025-06-28T19:39:55.025532Z",
     "iopub.status.idle": "2025-06-28T19:39:55.030579Z",
     "shell.execute_reply": "2025-06-28T19:39:55.029713Z"
    },
    "id": "DfQDGjtJI_tx",
    "papermill": {
     "duration": 0.014172,
     "end_time": "2025-06-28T19:39:55.031995",
     "exception": false,
     "start_time": "2025-06-28T19:39:55.017823",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#the output has to be prepared according to forced teacher training, so the inputs and targets are being\n",
    "#prepared accordingly\n",
    "def prepare(tokenized_summaries, start_token=1398, end_token=1399):\n",
    "    Y_input = []\n",
    "    Y_target = []\n",
    "    for seq in tokenized_summaries:\n",
    "        Y_input.append([start_token] + seq)\n",
    "        Y_target.append(seq + [end_token])\n",
    "    return Y_input, Y_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d955f003",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-28T19:39:55.047422Z",
     "iopub.status.busy": "2025-06-28T19:39:55.046798Z",
     "iopub.status.idle": "2025-06-28T19:39:55.052670Z",
     "shell.execute_reply": "2025-06-28T19:39:55.051740Z"
    },
    "id": "LiDmESgvRpzo",
    "papermill": {
     "duration": 0.015126,
     "end_time": "2025-06-28T19:39:55.054059",
     "exception": false,
     "start_time": "2025-06-28T19:39:55.038933",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_input , y_output = prepare(Y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d0e006c7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-28T19:39:55.068866Z",
     "iopub.status.busy": "2025-06-28T19:39:55.068535Z",
     "iopub.status.idle": "2025-06-28T19:39:55.087166Z",
     "shell.execute_reply": "2025-06-28T19:39:55.086233Z"
    },
    "id": "TccRtCwcSURY",
    "papermill": {
     "duration": 0.027873,
     "end_time": "2025-06-28T19:39:55.088819",
     "exception": false,
     "start_time": "2025-06-28T19:39:55.060946",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#paddinf all the tensors, finally getting the data ready for the model\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "X_padded = pad_sequences(X,maxlen=302, padding='post')          # encoder input\n",
    "Y_input_padded = pad_sequences(y_input, maxlen=102, padding='post')   # decoder input\n",
    "Y_target_padded = pad_sequences(y_output, maxlen=102, padding='post') # decoder target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "479bb514",
   "metadata": {
    "id": "8pw5WWhJS3PB",
    "papermill": {
     "duration": 0.006641,
     "end_time": "2025-06-28T19:39:55.102585",
     "exception": false,
     "start_time": "2025-06-28T19:39:55.095944",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "TRANSFORMER IMPLEMENTATION FUNCTIONS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "18108bfb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-28T19:39:55.117842Z",
     "iopub.status.busy": "2025-06-28T19:39:55.117006Z",
     "iopub.status.idle": "2025-06-28T19:39:55.126028Z",
     "shell.execute_reply": "2025-06-28T19:39:55.125093Z"
    },
    "id": "CyRqNrT5Smgj",
    "papermill": {
     "duration": 0.018054,
     "end_time": "2025-06-28T19:39:55.127343",
     "exception": false,
     "start_time": "2025-06-28T19:39:55.109289",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Self attention Block\n",
    "dropout = 0.2\n",
    "n_embd = 32\n",
    "# block_size = 302\n",
    "batch_size = 10\n",
    "head_size = 4\n",
    "vocab_size_e = 6000\n",
    "vocab_size_d = 6000\n",
    "# n_heads = 2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Head(nn.Module):\n",
    "    def __init__(self, block_size):\n",
    "        super().__init__()\n",
    "        self.key   = nn.Linear(n_embd , head_size, bias=False)\n",
    "        self.query = nn.Linear(n_embd , head_size, bias=False)\n",
    "        self.value = nn.Linear(n_embd , head_size, bias=False)\n",
    "\n",
    "        self.tril = torch.tril(torch.ones(block_size, block_size))  # (T, T)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "\n",
    "    def forward(self, X):\n",
    "        B, T, C = X.size()\n",
    "\n",
    "        assert T <= self.tril.size(0), f\"Sequence length {T} exceeds tril size {self.tril.size(0)}\"\n",
    "\n",
    "        # Step 1: Compute key, query, value\n",
    "        k = self.key(X)      # (B, T, head_size)\n",
    "        q = self.query(X)    # (B, T, head_size)\n",
    "\n",
    "        # Step 2: Compute attention scores\n",
    "        wei = q @ k.transpose(-2, -1) * (k.shape[-1] ** -0.5)  # (B, T, T)\n",
    "\n",
    "        # Step 3: Causal masking\n",
    "        mask = self.tril[:T, :T] == 0\n",
    "        wei = wei.masked_fill(mask.unsqueeze(0).to(X.device), float('-inf'))\n",
    "\n",
    "        # Step 4: Softmax to get weights\n",
    "        wei = F.softmax(wei, dim=-1)\n",
    "        wei = self.dropout(wei)\n",
    "\n",
    "        # Step 5: Weighted sum of values\n",
    "        v = self.value(X)        # (B, T, head_size)\n",
    "        out = wei @ v            # (B, T, head_size)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a02ba89d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-28T19:39:55.143741Z",
     "iopub.status.busy": "2025-06-28T19:39:55.142931Z",
     "iopub.status.idle": "2025-06-28T19:39:55.148375Z",
     "shell.execute_reply": "2025-06-28T19:39:55.147654Z"
    },
    "id": "aqZCAofya2iu",
    "papermill": {
     "duration": 0.014876,
     "end_time": "2025-06-28T19:39:55.149794",
     "exception": false,
     "start_time": "2025-06-28T19:39:55.134918",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class feedForward(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.layer1 = nn.Linear(n_embd, 4 * n_embd)\n",
    "    self.relu = nn.ReLU();\n",
    "    self.layer_f = nn.Linear(4*n_embd, n_embd);\n",
    "\n",
    "  def forward(self, x):\n",
    "      x = self.layer1(x);\n",
    "      x = self.relu(x);\n",
    "      x = self.layer_f(x);\n",
    "      return x;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "43848480",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-28T19:39:55.166088Z",
     "iopub.status.busy": "2025-06-28T19:39:55.164965Z",
     "iopub.status.idle": "2025-06-28T19:39:55.171484Z",
     "shell.execute_reply": "2025-06-28T19:39:55.170655Z"
    },
    "id": "GhfQ9saDby0Z",
    "papermill": {
     "duration": 0.015808,
     "end_time": "2025-06-28T19:39:55.172962",
     "exception": false,
     "start_time": "2025-06-28T19:39:55.157154",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "\n",
    "\n",
    "    def __init__(self, block_size):\n",
    "        super().__init__()\n",
    "\n",
    "        self.heads = nn.ModuleList([Head(block_size) for _ in range(8)])\n",
    "        self.proj = nn.Linear(n_embd, n_embd)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = torch.cat([h(x) for h in self.heads], dim=-1)\n",
    "        out = self.dropout(self.proj(out))\n",
    "        return out\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fefb7441",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-28T19:39:55.191224Z",
     "iopub.status.busy": "2025-06-28T19:39:55.190924Z",
     "iopub.status.idle": "2025-06-28T19:39:55.196785Z",
     "shell.execute_reply": "2025-06-28T19:39:55.195812Z"
    },
    "id": "EgpCM1m1jHI0",
    "papermill": {
     "duration": 0.017505,
     "end_time": "2025-06-28T19:39:55.198296",
     "exception": false,
     "start_time": "2025-06-28T19:39:55.180791",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class decoder_Block(nn.Module):\n",
    "    \"\"\" Transformer block: communication followed by computation \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        # n_embd: embedding dimension, n_head: the number of heads we'd like\n",
    "        super().__init__()\n",
    "        self.sa = MultiHeadAttention(102)\n",
    "        self.ffwd = feedForward()\n",
    "        self.ln1 = nn.LayerNorm()\n",
    "        self.ln2 = nn.LayerNorm()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.sa(self.ln1(x))\n",
    "        x = x + self.ffwd(self.ln2(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "36621271",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-28T19:39:55.215073Z",
     "iopub.status.busy": "2025-06-28T19:39:55.214760Z",
     "iopub.status.idle": "2025-06-28T19:39:55.220348Z",
     "shell.execute_reply": "2025-06-28T19:39:55.219399Z"
    },
    "id": "cevsIaDxkjwN",
    "papermill": {
     "duration": 0.014833,
     "end_time": "2025-06-28T19:39:55.221781",
     "exception": false,
     "start_time": "2025-06-28T19:39:55.206948",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class encoder_block(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "\n",
    "    self.sa = MultiHeadAttention(302)\n",
    "    self.ffwd = feedForward()\n",
    "    self.ln1 = nn.LayerNorm(n_embd)\n",
    "    self.ln2 = nn.LayerNorm(n_embd)\n",
    "\n",
    "  def forward(self, x):\n",
    "     x = x + self.sa(self.ln1(x))\n",
    "     x = x + self.ffwd(self.ln2(x))\n",
    "     return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "72e21f01",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-28T19:39:55.238082Z",
     "iopub.status.busy": "2025-06-28T19:39:55.237809Z",
     "iopub.status.idle": "2025-06-28T19:39:55.244381Z",
     "shell.execute_reply": "2025-06-28T19:39:55.243528Z"
    },
    "id": "ElrMT7-zmwyk",
    "papermill": {
     "duration": 0.015997,
     "end_time": "2025-06-28T19:39:55.245849",
     "exception": false,
     "start_time": "2025-06-28T19:39:55.229852",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class crossAttention(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.key = nn.Linear(n_embd, head_size, bias=False)\n",
    "    self.query = nn.Linear(n_embd, head_size, bias=False)\n",
    "    self.value = nn.Linear(n_embd, head_size, bias = False)\n",
    "    self.l_f = nn.Linear(head_size, n_embd, bias = False)\n",
    "\n",
    "\n",
    "    self.dropout = nn.Dropout(dropout);\n",
    "\n",
    "  def forward(self, X, Y):\n",
    "     k = self.key(X);\n",
    "     q = self.query(Y);\n",
    "\n",
    "     wei = q @ k.transpose(-2, -1) * k.shape[-1]**-0.5\n",
    "\n",
    "     wei = F.softmax(wei, dim=-1)\n",
    "     v = self.value(X);\n",
    "     out =  wei@v;\n",
    "     return self.l_f(out);\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cbd81e73",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-28T19:39:55.260467Z",
     "iopub.status.busy": "2025-06-28T19:39:55.260178Z",
     "iopub.status.idle": "2025-06-28T19:39:55.265756Z",
     "shell.execute_reply": "2025-06-28T19:39:55.265047Z"
    },
    "id": "dNmUDsyb075M",
    "papermill": {
     "duration": 0.014457,
     "end_time": "2025-06-28T19:39:55.267002",
     "exception": false,
     "start_time": "2025-06-28T19:39:55.252545",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class decoder_Block(nn.Module):\n",
    "    \"\"\" Transformer block: communication followed by computation \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        # n_embd: embedding dimension, n_head: the number of heads we'd like\n",
    "        super().__init__()\n",
    "\n",
    "        self.sa = MultiHeadAttention(102)\n",
    "        self.ffwd = feedForward()\n",
    "        self.ln1 = nn.LayerNorm(n_embd)\n",
    "        self.cross =  crossAttention();\n",
    "        self.ln2 = nn.LayerNorm(n_embd)\n",
    "\n",
    "\n",
    "    def forward(self, x, X_enc):\n",
    "        x = x + self.sa(self.ln1(x))\n",
    "        x = x+ self.cross(X_enc, x);\n",
    "        x = x + self.ffwd(self.ln2(x))\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "95b0e5b8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-28T19:39:55.282350Z",
     "iopub.status.busy": "2025-06-28T19:39:55.281810Z",
     "iopub.status.idle": "2025-06-28T19:39:55.287808Z",
     "shell.execute_reply": "2025-06-28T19:39:55.287054Z"
    },
    "id": "1v-FV54K2rCT",
    "papermill": {
     "duration": 0.015302,
     "end_time": "2025-06-28T19:39:55.289156",
     "exception": false,
     "start_time": "2025-06-28T19:39:55.273854",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "class Encoder(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # each token directly reads off the logits for the next token from a lookup table\n",
    "        self.token_embedding_table = nn.Embedding(6000, n_embd, padding_idx =0)\n",
    "        self.position_embedding_table = nn.Embedding(302, n_embd)\n",
    "        self.blocks = nn.Sequential(*[encoder_block() for _ in range(2)])\n",
    "        self.ln_f = nn.LayerNorm(n_embd) # final layer norm\n",
    "\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        B, T = idx.shape\n",
    "        #10000\n",
    "        # idx and targets are both (B,T) tensor of integers\n",
    "        tok_emb = self.token_embedding_table(idx) # (B,T,C)##\n",
    "        pos_emb = self.position_embedding_table(torch.arange(T, device=device)) # (T,C)\n",
    "        x = tok_emb + pos_emb # (B,T,C)\n",
    "        x = self.blocks(x) # (B,T,C)\n",
    "        x = self.ln_f(x) # (B,T,C)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "80c1d103",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-28T19:39:55.304234Z",
     "iopub.status.busy": "2025-06-28T19:39:55.303478Z",
     "iopub.status.idle": "2025-06-28T19:39:55.310035Z",
     "shell.execute_reply": "2025-06-28T19:39:55.309105Z"
    },
    "id": "hNmJWcbZX2Uh",
    "papermill": {
     "duration": 0.015326,
     "end_time": "2025-06-28T19:39:55.311365",
     "exception": false,
     "start_time": "2025-06-28T19:39:55.296039",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "       \n",
    "        self.token_embedding_table = nn.Embedding(6000, n_embd, padding_idx =0)\n",
    "        self.position_embedding_table = nn.Embedding(102, n_embd)\n",
    "        self.blocks = nn.Sequential(*[decoder_Block() for _ in range(2)])\n",
    "        self.ln_f = nn.LayerNorm(n_embd) # final layer norm\n",
    "        self.lm_head = nn.Linear(n_embd, 6000)\n",
    "\n",
    "    def forward(self, idx,x_enc, targets=None):\n",
    "        B, T = idx.shape\n",
    "\n",
    "\n",
    "        tok_emb = self.token_embedding_table(idx) # (B,T,C)\n",
    "        pos_emb = self.position_embedding_table(torch.arange(T, device=device)) # (T,C)####\n",
    "        x = tok_emb + pos_emb # (B,T,C)\n",
    "        for block in self.blocks:\n",
    "\n",
    "          x = block(x, x_enc)\n",
    "\n",
    "        x = self.ln_f(x) # (B,T,C)\n",
    "        return self.lm_head(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4bd38c16",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-28T19:39:55.326454Z",
     "iopub.status.busy": "2025-06-28T19:39:55.326170Z",
     "iopub.status.idle": "2025-06-28T19:39:55.331844Z",
     "shell.execute_reply": "2025-06-28T19:39:55.330923Z"
    },
    "id": "9ZcfKn66kUHH",
    "papermill": {
     "duration": 0.014819,
     "end_time": "2025-06-28T19:39:55.333217",
     "exception": false,
     "start_time": "2025-06-28T19:39:55.318398",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.encoder = Encoder();\n",
    "    self.decoder = Decoder();\n",
    "\n",
    "  def forward(self, X,y_in, y_target, loss_f):\n",
    "    x_enc = self.encoder(X);\n",
    "    y_out = self.decoder(y_in, x_enc);\n",
    "    loss = loss_f(y_out.view(-1, y_out.shape[-1]), y_target.view(-1))\n",
    "    return y_out, loss;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c746de78",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-28T19:39:55.348067Z",
     "iopub.status.busy": "2025-06-28T19:39:55.347806Z",
     "iopub.status.idle": "2025-06-28T19:48:20.343892Z",
     "shell.execute_reply": "2025-06-28T19:48:20.342757Z"
    },
    "id": "BnJ9wg8pAz09",
    "outputId": "b5aec32a-b50f-4a22-9349-d049ea0c655a",
    "papermill": {
     "duration": 505.021592,
     "end_time": "2025-06-28T19:48:20.361815",
     "exception": false,
     "start_time": "2025-06-28T19:39:55.340223",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.060674667358398\n",
      "17.76961612701416\n",
      "26.132694244384766\n",
      "34.184327125549316\n",
      "41.92098426818848\n",
      "49.40656280517578\n",
      "56.64831781387329\n",
      "63.61801815032959\n",
      "70.38274574279785\n",
      "76.98796033859253\n",
      "83.39785623550415\n",
      "89.65489673614502\n",
      "95.7546558380127\n",
      "101.73001718521118\n",
      "107.5423583984375\n",
      "113.32670211791992\n",
      "118.9329628944397\n",
      "124.4528341293335\n",
      "129.88997650146484\n",
      "135.16114139556885\n",
      "140.42226600646973\n",
      "145.56894063949585\n",
      "150.61415338516235\n",
      "155.61022901535034\n",
      "160.49369621276855\n",
      "165.2644443511963\n",
      "169.97202348709106\n",
      "174.55251216888428\n",
      "179.11578035354614\n",
      "183.61120223999023\n",
      "188.00010108947754\n",
      "192.28986883163452\n",
      "196.48512935638428\n",
      "200.65358209609985\n",
      "204.71244955062866\n",
      "208.6753752231598\n",
      "212.51839184761047\n",
      "216.23669719696045\n",
      "219.9153654575348\n",
      "223.60316348075867\n",
      "227.15614438056946\n",
      "230.71815872192383\n",
      "234.13365364074707\n",
      "237.50424575805664\n",
      "240.77190732955933\n",
      "243.9594919681549\n",
      "246.99234080314636\n",
      "249.95424056053162\n",
      "252.85032629966736\n",
      "255.6084725856781\n",
      "258.35345220565796\n",
      "261.1009736061096\n",
      "263.7110540866852\n",
      "266.35107493400574\n",
      "268.847629070282\n",
      "271.29939460754395\n",
      "273.57029461860657\n",
      "275.8345699310303\n",
      "277.98414301872253\n",
      "280.0703055858612\n",
      "282.0589989423752\n",
      "284.01352179050446\n",
      "285.9256035089493\n",
      "287.73050796985626\n",
      "289.38827776908875\n",
      "291.2413640022278\n",
      "292.9395353794098\n",
      "294.52308452129364\n",
      "295.9660577774048\n",
      "297.4140053987503\n",
      "298.7535046339035\n",
      "300.0260616540909\n",
      "301.300448179245\n",
      "302.5261746644974\n",
      "303.7036381959915\n",
      "304.8549655675888\n",
      "306.0074670314789\n",
      "307.00824546813965\n",
      "308.01717579364777\n",
      "309.1860451698303\n",
      "310.1613782644272\n",
      "310.9326860308647\n",
      "311.8337800502777\n",
      "312.7611126899719\n",
      "313.6258187890053\n",
      "314.5556736588478\n",
      "315.2265976667404\n",
      "316.32419192790985\n",
      "317.0059009194374\n",
      "317.62863236665726\n",
      "318.23988634347916\n",
      "318.85413402318954\n",
      "319.7729539871216\n",
      "320.41409009695053\n",
      "321.01489263772964\n",
      "321.56343525648117\n",
      "322.15718591213226\n",
      "322.86734586954117\n",
      "323.5081803202629\n",
      "323.96468555927277\n",
      "324.48425632715225\n",
      "325.2539724111557\n",
      "325.76542872190475\n",
      "326.4851568341255\n",
      "327.1811645627022\n",
      "327.7432126402855\n",
      "328.34072428941727\n",
      "329.31354463100433\n",
      "330.00584852695465\n",
      "330.4715641140938\n",
      "331.05184960365295\n",
      "331.46542805433273\n",
      "332.0073990225792\n",
      "332.42609494924545\n",
      "332.9020077586174\n",
      "333.48637068271637\n",
      "333.9204066693783\n",
      "334.38311952352524\n",
      "334.82934632897377\n",
      "335.2553634047508\n",
      "336.1481856703758\n",
      "336.58700436353683\n",
      "337.10260170698166\n",
      "337.62421464920044\n",
      "338.1104741990566\n",
      "338.74527058005333\n",
      "339.0866289138794\n",
      "339.8281480669975\n",
      "340.49195516109467\n",
      "341.0289715528488\n",
      "341.40781381726265\n",
      "341.8311347067356\n",
      "342.3855215013027\n",
      "342.8013007938862\n",
      "343.41878870129585\n",
      "344.05030915141106\n",
      "344.5389059782028\n",
      "345.04207956790924\n",
      "345.3499131500721\n",
      "345.9061323106289\n",
      "346.29014390707016\n",
      "346.79164004325867\n",
      "347.2837393581867\n",
      "347.72682908177376\n",
      "348.0569877028465\n",
      "348.5334174335003\n",
      "349.0234873890877\n",
      "349.59362334012985\n",
      "350.1183207631111\n",
      "350.74787950515747\n",
      "351.20905950665474\n",
      "352.0948404967785\n",
      "352.5934202373028\n",
      "353.01295933127403\n",
      "353.40863436460495\n",
      "353.91557252407074\n",
      "354.3290685713291\n",
      "354.6470704972744\n",
      "354.9873688220978\n",
      "355.4124310910702\n",
      "355.9060646891594\n",
      "356.34056079387665\n",
      "356.66096422076225\n",
      "357.12962064146996\n",
      "357.57699978351593\n",
      "358.3261461853981\n",
      "358.6466270685196\n",
      "359.16135585308075\n",
      "359.6342248916626\n",
      "360.19915610551834\n",
      "360.456307977438\n",
      "360.85770094394684\n",
      "361.2639720439911\n",
      "361.563907712698\n",
      "362.2422078549862\n",
      "362.66479498147964\n",
      "362.9599258005619\n",
      "363.38003969192505\n",
      "363.95470571517944\n",
      "364.25818714499474\n",
      "364.65082809329033\n",
      "365.0427243709564\n",
      "365.4408819079399\n",
      "365.8789315521717\n",
      "366.34560814499855\n",
      "366.81772112846375\n",
      "367.50117087364197\n",
      "368.03245174884796\n",
      "368.63560074567795\n",
      "369.12297451496124\n",
      "369.55688270926476\n",
      "369.88891646265984\n",
      "370.21734341979027\n",
      "370.55785220861435\n",
      "370.8188792169094\n",
      "371.2550112605095\n",
      "371.66708463430405\n",
      "372.1901160478592\n",
      "372.6887960135937\n",
      "373.14658200740814\n",
      "373.6294065117836\n",
      "373.9246223270893\n",
      "374.4113608300686\n",
      "374.73144194483757\n",
      "375.2547141611576\n",
      "375.70928728580475\n",
      "376.0917090475559\n",
      "376.52051588892937\n",
      "376.8959063589573\n",
      "377.2132142186165\n",
      "377.56599125266075\n",
      "377.9564171731472\n",
      "378.4343344569206\n",
      "378.8455114066601\n",
      "379.2327648103237\n",
      "379.5662139058113\n",
      "379.9473848640919\n",
      "380.38792207837105\n",
      "380.96454045176506\n",
      "381.45758748054504\n",
      "381.9127842783928\n",
      "382.26712143421173\n",
      "382.65561243891716\n",
      "383.39304515719414\n",
      "383.6476527750492\n",
      "384.3971854150295\n",
      "384.87377390265465\n",
      "385.5004238188267\n",
      "385.78724908828735\n",
      "386.24806874990463\n",
      "386.77068650722504\n",
      "387.0739395618439\n",
      "387.6170023679733\n",
      "388.0388693511486\n",
      "388.6946929395199\n",
      "388.9654431641102\n",
      "389.4456567764282\n",
      "389.883259087801\n",
      "390.1615816652775\n",
      "390.627967864275\n",
      "391.0004638135433\n",
      "391.2495709359646\n",
      "391.55462741851807\n",
      "391.87321361899376\n",
      "392.29681223630905\n",
      "392.90253061056137\n",
      "393.35609859228134\n",
      "393.7385142445564\n",
      "394.21198174357414\n",
      "394.6167510151863\n",
      "395.0203580260277\n",
      "395.2556658834219\n",
      "395.7188692241907\n",
      "396.0127650350332\n",
      "396.28556330502033\n",
      "396.62760062515736\n",
      "397.0281956344843\n",
      "397.2771432250738\n",
      "397.70071925222874\n",
      "398.0437914580107\n",
      "398.3679282218218\n",
      "398.5885393023491\n",
      "398.94038221240044\n",
      "399.4942919909954\n",
      "399.77554428577423\n",
      "400.167749106884\n",
      "400.4495905637741\n",
      "400.9325273036957\n",
      "401.36650785803795\n",
      "401.67968437075615\n",
      "401.91686333715916\n",
      "402.1855623871088\n",
      "402.5516974776983\n",
      "402.8723625987768\n",
      "403.21826957166195\n",
      "403.6972540766001\n",
      "403.9632674306631\n",
      "404.30388517677784\n",
      "404.77922900021076\n",
      "405.0744497925043\n",
      "405.2980493456125\n",
      "405.68463139235973\n",
      "406.0527846366167\n",
      "406.4090719074011\n",
      "406.59434139728546\n",
      "406.7832242101431\n",
      "407.1537852436304\n",
      "407.4194338172674\n",
      "407.6634638905525\n",
      "407.9445454478264\n",
      "408.3474605381489\n",
      "408.8946646153927\n",
      "409.11230881512165\n",
      "409.3169229924679\n",
      "409.5217275619507\n",
      "409.94068372249603\n",
      "410.366751909256\n",
      "410.5731907635927\n",
      "410.92675568163395\n",
      "411.2077571898699\n",
      "411.4523123204708\n",
      "411.8217468559742\n",
      "412.2099390923977\n",
      "412.45903600752354\n",
      "412.68449506163597\n",
      "412.9485527873039\n",
      "413.37945744395256\n",
      "413.66026455163956\n",
      "413.87446551024914\n",
      "414.4762228578329\n",
      "414.8486093431711\n",
      "415.1056919544935\n",
      "415.3610583692789\n",
      "415.7844523638487\n",
      "416.16594760119915\n",
      "416.4084569811821\n",
      "416.76970890164375\n",
      "417.0989038348198\n",
      "417.42830207943916\n",
      "417.83442002534866\n",
      "418.14586651325226\n",
      "418.43491435050964\n",
      "418.81518402695656\n",
      "419.07466664910316\n",
      "419.77580562233925\n",
      "420.0380038022995\n",
      "420.52773746848106\n",
      "421.10026356577873\n",
      "421.509667545557\n",
      "421.8687037229538\n",
      "422.09482711553574\n",
      "422.5678685605526\n",
      "422.74129843711853\n",
      "423.00502774119377\n",
      "423.2720856368542\n",
      "423.6172086298466\n",
      "424.0943883359432\n",
      "424.3284156769514\n",
      "424.80214689671993\n",
      "425.0798137038946\n",
      "425.46068082749844\n",
      "425.97161661088467\n",
      "426.3485101610422\n",
      "426.6537492722273\n",
      "426.94728468358517\n",
      "427.1908057183027\n",
      "427.5143062621355\n",
      "427.730236902833\n",
      "428.00628642737865\n",
      "428.425228908658\n",
      "428.6634151041508\n",
      "429.01913183927536\n",
      "429.28918221592903\n",
      "429.6480284035206\n",
      "429.9274029433727\n",
      "430.2403596639633\n",
      "430.63435250520706\n",
      "430.9168019592762\n",
      "431.3563225865364\n",
      "431.5413349568844\n",
      "431.73706939816475\n",
      "432.11806759238243\n",
      "432.4711519777775\n",
      "432.85123112797737\n",
      "433.0672519057989\n",
      "433.4074735790491\n",
      "433.6880941838026\n",
      "433.87626752257347\n",
      "434.01965664327145\n",
      "434.3662719577551\n",
      "434.69575898349285\n",
      "435.16276283562183\n",
      "435.6224766820669\n",
      "435.9276045113802\n",
      "436.3188946992159\n",
      "436.5867575854063\n",
      "436.83959652483463\n",
      "437.07172541320324\n",
      "437.45683439075947\n",
      "437.6709741950035\n",
      "437.87021465599537\n",
      "438.3386208862066\n",
      "438.5896635502577\n",
      "439.009528234601\n",
      "439.25680485367775\n",
      "439.45701456069946\n",
      "439.713269084692\n",
      "440.00977805256844\n",
      "440.18322905898094\n",
      "440.3539932668209\n",
      "440.6788464784622\n",
      "Epoch 0 - Avg Loss: 1.1271\n",
      "Epoch 1 - Avg Loss: 0.2639\n",
      "Epoch 2 - Avg Loss: 0.2389\n",
      "Epoch 3 - Avg Loss: 0.2297\n",
      "Epoch 4 - Avg Loss: 0.2221\n",
      "Epoch 5 - Avg Loss: 0.2157\n",
      "Epoch 6 - Avg Loss: 0.2088\n",
      "Epoch 7 - Avg Loss: 0.1998\n",
      "Epoch 8 - Avg Loss: 0.1917\n",
      "Epoch 9 - Avg Loss: 0.1832\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Move all data to tensors first (CPU for now)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "x_tensor  =   torch.tensor(X_padded, dtype=torch.long).to(device)\n",
    "y_in_tensor = torch.tensor(Y_input_padded, dtype=torch.long).to(device)\n",
    "y_tgt_tensor = torch.tensor(Y_target_padded, dtype=torch.long).to(device)\n",
    "\n",
    "# Create dataset and dataloader\n",
    "dataset = TensorDataset(x_tensor, y_in_tensor, y_tgt_tensor)\n",
    "batch_size = 4\n",
    "loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Device setup\n",
    "\n",
    "\n",
    "# Initialize model and optimizer\n",
    "model = Model().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_f = nn.CrossEntropyLoss()\n",
    "import os\n",
    "\n",
    "# Directory to save checkpoints\n",
    "os.makedirs(\"checkpoints\", exist_ok=True)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(10):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "\n",
    "    for x_batch, y_in_batch, y_tgt_batch in loader:\n",
    "        # Move batch to device\n",
    "        x_batch = x_batch.to(device)\n",
    "        y_in_batch = y_in_batch.to(device)\n",
    "        y_tgt_batch = y_tgt_batch.to(device)\n",
    "\n",
    "        # Forward pass and loss\n",
    "        y_out, loss_val = model(x_batch, y_in_batch, y_tgt_batch, loss_f)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss_val.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss_val.item()\n",
    "        if epoch==0:\n",
    "            print(total_loss)\n",
    "\n",
    "    avg_loss = total_loss / len(loader)\n",
    "    \n",
    "    if epoch % 1 == 0:\n",
    "        print(f\"Epoch {epoch} - Avg Loss: {avg_loss:.4f}\")\n",
    "        \n",
    "        # Save the model\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': avg_loss,\n",
    "        }, f\"checkpoints/model_epoch_{epoch}.pt\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a923ceb7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-28T19:48:20.397736Z",
     "iopub.status.busy": "2025-06-28T19:48:20.397113Z",
     "iopub.status.idle": "2025-06-28T19:48:20.497811Z",
     "shell.execute_reply": "2025-06-28T19:48:20.496713Z"
    },
    "papermill": {
     "duration": 0.119502,
     "end_time": "2025-06-28T19:48:20.499171",
     "exception": false,
     "start_time": "2025-06-28T19:48:20.379669",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from epoch 9 with loss 0.1832\n"
     ]
    }
   ],
   "source": [
    "model = Model().to(device)                 # same architecture as before\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)  # same optimizer config\n",
    "checkpoint = torch.load(\"/kaggle/working/checkpoints/model_epoch_9.pt\")\n",
    "\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "\n",
    "epoch = checkpoint['epoch']\n",
    "loss = checkpoint['loss']\n",
    "\n",
    "print(f\"Loaded model from epoch {epoch} with loss {loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce85d84",
   "metadata": {
    "papermill": {
     "duration": 0.01572,
     "end_time": "2025-06-28T19:48:20.530979",
     "exception": false,
     "start_time": "2025-06-28T19:48:20.515259",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8d779d93",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-28T19:48:20.564035Z",
     "iopub.status.busy": "2025-06-28T19:48:20.563725Z",
     "iopub.status.idle": "2025-06-28T19:48:20.568357Z",
     "shell.execute_reply": "2025-06-28T19:48:20.567673Z"
    },
    "papermill": {
     "duration": 0.022729,
     "end_time": "2025-06-28T19:48:20.569578",
     "exception": false,
     "start_time": "2025-06-28T19:48:20.546849",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_tensor = torch.tensor(X_padded, dtype=torch.long, device=\"cpu\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c0d3f2c2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-28T19:48:20.602332Z",
     "iopub.status.busy": "2025-06-28T19:48:20.602036Z",
     "iopub.status.idle": "2025-06-28T19:48:20.607233Z",
     "shell.execute_reply": "2025-06-28T19:48:20.606465Z"
    },
    "papermill": {
     "duration": 0.023191,
     "end_time": "2025-06-28T19:48:20.608603",
     "exception": false,
     "start_time": "2025-06-28T19:48:20.585412",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['model_epoch_2.pt', 'model_epoch_7.pt', 'model_epoch_1.pt', 'model_epoch_9.pt', 'model_epoch_6.pt', 'model_epoch_8.pt', 'model_epoch_4.pt', 'model_epoch_0.pt', 'model_epoch_3.pt', 'model_epoch_5.pt']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "files = os.listdir(\"/kaggle/working/checkpoints\")\n",
    "print(files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e4557c09",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-28T19:48:20.642000Z",
     "iopub.status.busy": "2025-06-28T19:48:20.641692Z",
     "iopub.status.idle": "2025-06-28T19:48:24.267022Z",
     "shell.execute_reply": "2025-06-28T19:48:24.266009Z"
    },
    "papermill": {
     "duration": 3.643495,
     "end_time": "2025-06-28T19:48:24.268368",
     "exception": false,
     "start_time": "2025-06-28T19:48:20.624873",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zipping complete: /kaggle/working/checkpoint.zip\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import os\n",
    "\n",
    "folder_path = \"/kaggle/working/checkpoints\"\n",
    "zip_path = \"/kaggle/working/checkpoint.zip\"\n",
    "\n",
    "# Create a zip archive of the folder\n",
    "with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "    for root, dirs, files in os.walk(folder_path):\n",
    "        for file in files:\n",
    "            file_path = os.path.join(root, file)\n",
    "            arcname = os.path.relpath(file_path, folder_path)\n",
    "            zipf.write(file_path, arcname)\n",
    "\n",
    "print(\"Zipping complete:\", zip_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2f8d414a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-28T19:48:24.301943Z",
     "iopub.status.busy": "2025-06-28T19:48:24.301634Z",
     "iopub.status.idle": "2025-06-28T19:48:24.308706Z",
     "shell.execute_reply": "2025-06-28T19:48:24.307900Z"
    },
    "papermill": {
     "duration": 0.025266,
     "end_time": "2025-06-28T19:48:24.310056",
     "exception": false,
     "start_time": "2025-06-28T19:48:24.284790",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "    # Step 3: Initialize decoder input\n",
    "def translate(model, tokenizer, sentence, start_token, end_token, device='cpu', max_len=100):\n",
    "    \n",
    "    # Tokenize input\n",
    "    X_token = tokenizer.texts_to_sequences([sentence])\n",
    "    X_tensor = torch.tensor(X_token, dtype=torch.long).to(device)\n",
    "\n",
    "    # Encode\n",
    "    encoder_output = model.encoder(X_tensor)\n",
    "\n",
    "    # Initialize decoder\n",
    "    decoder_input = torch.tensor([[start_token]], dtype=torch.long).to(device)\n",
    "    output_tokens = []\n",
    "\n",
    "    for _ in range(max_len):\n",
    "        # Decode\n",
    "        logits = model.decoder(decoder_input, encoder_output)  # (1, seq_len, vocab_size)\n",
    "        probs = F.softmax(logits[:, -1, :], dim=-1)             # only last token\n",
    "\n",
    "        # Sample next token\n",
    "        next_token = torch.argmax(probs, dim=-1).item()\n",
    "\n",
    "\n",
    "        if next_token == end_token:\n",
    "            break\n",
    "\n",
    "        output_tokens.append(next_token)\n",
    "\n",
    "        # Append next token to decoder input\n",
    "        decoder_input = torch.cat(\n",
    "            [decoder_input, torch.tensor([[next_token]], dtype=torch.long).to(device)],\n",
    "            dim=1\n",
    "        )\n",
    "\n",
    "    return output_tokens\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fd6e3ca3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-28T19:48:24.345176Z",
     "iopub.status.busy": "2025-06-28T19:48:24.344871Z",
     "iopub.status.idle": "2025-06-28T19:48:24.385526Z",
     "shell.execute_reply": "2025-06-28T19:48:24.384346Z"
    },
    "papermill": {
     "duration": 0.060864,
     "end_time": "2025-06-28T19:48:24.387090",
     "exception": false,
     "start_time": "2025-06-28T19:48:24.326226",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translated: ['the you']\n"
     ]
    }
   ],
   "source": [
    "sen = \"  We've bought these many times from Amazon because we're government employees living overseas and can't get them in the country we are assigned to.  They've always been fresh and tasty, packed well and arrive in a timely manner\"\n",
    "output_ids = translate(model, tokenizer,sen, 1398, 1399)\n",
    "translated_text = tokenizer.sequences_to_texts([output_ids])\n",
    "print(\"Translated:\", translated_text)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 18,
     "isSourceIdPinned": false,
     "sourceId": 2157,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31040,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 549.404331,
   "end_time": "2025-06-28T19:48:27.568406",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-06-28T19:39:18.164075",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
